{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "zdACgs491cs2",
    "outputId": "b31042ef-845b-46b8-c783-185e96b135f7",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds\n",
    "rnd.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "sXWBVGWnpity",
    "outputId": "afa90d4d-fed7-43b8-bcba-48c95d600ad5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question pairs:  404351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"questions.csv\")\n",
    "N = len(data)\n",
    "print('Number of question pairs: ', N)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "z00A7vEMpit1",
    "outputId": "c12ae7e8-a959-4f56-aa29-6ad34abc1c81",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 300000 Test set: 10240\n"
     ]
    }
   ],
   "source": [
    "N_train = 300000\n",
    "N_test = 10240\n",
    "data_train = data[:N_train]\n",
    "data_test = data[N_train:N_train + N_test]\n",
    "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
    "del (data)  # remove to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Xi_TwXxxpit4",
    "outputId": "f146046f-9c0d-4d8a-ecf8-8d6a4a5371f7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "Indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
     ]
    }
   ],
   "source": [
    "td_index = data_train['is_duplicate'] == 1\n",
    "td_index = [i for i, x in enumerate(td_index) if x]\n",
    "print('Number of duplicate questions: ', len(td_index))\n",
    "print('Indexes of first ten duplicate questions:', td_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "3I9oXSsKpit7",
    "outputId": "6f6bd3a1-219f-4fb3-a524-450c38bf44ba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['question1'][5])\n",
    "print(data_train['question2'][5])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "XHpZO58Dss_v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1_train = np.array(data_train['question1'][td_index])\n",
    "Q2_train = np.array(data_train['question2'][td_index])\n",
    "\n",
    "Q1_test = np.array(data_test['question1'])\n",
    "Q2_test = np.array(data_test['question2'])\n",
    "y_test  = np.array(data_test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "joyrS1XEpLWn",
    "outputId": "3257cde7-3164-40d9-910e-fa91eae917a0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING QUESTIONS:\n",
      "\n",
      "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
      "\n",
      "Question 1:  What would a Trump presidency mean for current international masterâ€™s students on an F1 visa?\n",
      "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
      "\n",
      "TESTING QUESTIONS:\n",
      "\n",
      "Question 1:  How do I prepare for interviews for cse?\n",
      "Question 2:  What is the best way to prepare for cse? \n",
      "\n",
      "is_duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_train[0])\n",
    "print('Question 2: ', Q2_train[0], '\\n')\n",
    "print('Question 1: ', Q1_train[5])\n",
    "print('Question 2: ', Q2_train[5], '\\n')\n",
    "\n",
    "print('TESTING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_test[0])\n",
    "print('Question 2: ', Q2_test[0], '\\n')\n",
    "print('is_duplicate =', y_test[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "The length of the training set is:   89188\n",
      "The length of the validation set is:  22298\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "cut_off = int(len(Q1_train) * 0.8)\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
    "val_Q1, val_Q2 = Q1_train[cut_off:], Q2_train[cut_off:]\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "text_vectorization = tf.keras.layers.TextVectorization(output_mode='int',split='whitespace', standardize='strip_punctuation')\n",
    "text_vectorization.adapt(np.concatenate((Q1_train,Q2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36224\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {text_vectorization.vocabulary_size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question in the train set:\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "\n",
      "encoded version:\n",
      "tf.Tensor(\n",
      "[ 6984     6   178    10  8988  2442 35393   761    13  6636 28205    31\n",
      "    28   483    45    98], shape=(16,), dtype=int64) \n",
      "\n",
      "first question in the test set:\n",
      "\n",
      "How do I prepare for interviews for cse? \n",
      "\n",
      "encoded version:\n",
      "tf.Tensor([    4     8     6   160    17  2079    17 11775], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print('first question in the train set:\\n')\n",
    "print(Q1_train[0], '\\n') \n",
    "print('encoded version:')\n",
    "print(text_vectorization(Q1_train[0]),'\\n')\n",
    "\n",
    "print('first question in the test set:\\n')\n",
    "print(Q1_test[0], '\\n')\n",
    "print('encoded version:')\n",
    "print(text_vectorization(Q1_test[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def Siamese(text_vectorizer, vocab_size=36224, d_feature=128):\n",
    "    \"\"\"Returns a Siamese model.\n",
    "\n",
    "    Args:\n",
    "        text_vectorizer (TextVectorization): TextVectorization instance, already adapted to your training data.\n",
    "        vocab_size (int, optional): Length of the vocabulary. Defaults to 36224, which is the vocabulary size for your case.\n",
    "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
    "        \n",
    "    Returns:\n",
    "        tf.model.Model: A Siamese model. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    branch = tf.keras.models.Sequential(name='sequential') \n",
    "    \n",
    "    branch.add(text_vectorizer)\n",
    "    branch.add(tf.keras.layers.Embedding(vocab_size, d_feature, name='embedding'))\n",
    "    branch.add(tf.keras.layers.LSTM(d_feature, return_sequences = True, name='LSTM'))\n",
    "    branch.add(tf.keras.layers.GlobalAveragePooling1D(name='mean'))\n",
    "    branch.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x), name='out'))\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(1, dtype=tf.string, name='input_1')\n",
    "    input2 = tf.keras.layers.Input(1, dtype=tf.string, name='input_2')\n",
    "\n",
    "    branch1 = branch(input1)\n",
    "    branch2 = branch(input2)\n",
    "\n",
    "    conc = tf.keras.layers.Concatenate(axis=1, name='conc_1_2')([branch1, branch2]) \n",
    "    \n",
    "    return tf.keras.models.Model(inputs=[input1, input2], outputs=conc, name=\"SiameseModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "es2gfwZypiul"
   },
   "source": [
    "Setup the Siamese network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "kvQ_jf52-JAn",
    "outputId": "d409460d-2ffb-4ae6-8745-ddcfa1d892ad",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseModel\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 128)                  4768256   ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conc_1_2 (Concatenate)      (None, 256)                  0         ['sequential[0][0]',          \n",
      "                                                                     'sequential[1][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4768256 (18.19 MB)\n",
      "Trainable params: 4768256 (18.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         4636672   \n",
      "                                                                 \n",
      " LSTM (LSTM)                 (None, None, 128)         131584    \n",
      "                                                                 \n",
      " mean (GlobalAveragePooling  (None, 128)               0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " out (Lambda)                (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4768256 (18.19 MB)\n",
      "Trainable params: 4768256 (18.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check the model\n",
    "model = Siamese(text_vectorization, vocab_size=text_vectorization.vocabulary_size())\n",
    "model.build(input_shape=None)\n",
    "model.summary()\n",
    "model.get_layer(name='sequential').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def TripletLossFn(v1, v2,  margin=0.25):\n",
    "    \"\"\"Custom Loss function.\n",
    "\n",
    "    Args:\n",
    "        v1 (numpy.ndarray or Tensor): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
    "        v2 (numpy.ndarray or Tensor): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
    "        margin (float, optional): Desired margin. Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss (numpy.ndarray or Tensor)\n",
    "    \"\"\"\n",
    "   \n",
    "    scores = tf.linalg.matmul(v2, v1, transpose_b=True)\n",
    "\n",
    "    batch_size = tf.cast(tf.shape(v1)[0], scores.dtype) \n",
    "\n",
    "    positive = tf.linalg.diag_part(scores)\n",
    "\n",
    "    negative_zero_on_duplicate = scores - tf.linalg.diag(positive)\n",
    "\n",
    "    mean_negative = tf.math.reduce_sum(negative_zero_on_duplicate, axis=1) / (batch_size - 1)\n",
    "\n",
    "    mask_exclude_positives = tf.cast((tf.eye(batch_size) == 1) | (negative_zero_on_duplicate > tf.expand_dims(positive, 1)), scores.dtype)\n",
    "\n",
    "    negative_without_positive = negative_zero_on_duplicate - mask_exclude_positives * 2.0\n",
    "\n",
    "    closest_negative = tf.math.reduce_max(negative_without_positive, axis=1)\n",
    "\n",
    "    triplet_loss1 = tf.maximum(margin - positive + closest_negative, 0.0)\n",
    "    triplet_loss2 = tf.maximum(margin - positive + mean_negative, 0.0)\n",
    "\n",
    "    triplet_loss = tf.math.reduce_sum(triplet_loss1 + triplet_loss2)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss: 0.7035076825158911\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
    "v2 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
    "print(\"Triplet Loss:\", TripletLossFn(v1,v2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def TripletLoss(labels, out, margin=0.25):\n",
    "    _, out_size = out.shape # get embedding size\n",
    "    v1 = out[:,:int(out_size/2)] # Extract v1 from out\n",
    "    v2 = out[:,int(out_size/2):] # Extract v2 from out\n",
    "    return TripletLossFn(v1, v2, margin=margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(((train_Q1, train_Q2),tf.constant([1]*len(train_Q1))))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(((val_Q1, val_Q2),tf.constant([1]*len(val_Q1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "deletable": false,
    "id": "-3KXjmBo_6Xa",
    "outputId": "9d57f731-1534-4218-e744-783359d5cd19",
    "scrolled": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(Siamese, TripletLoss, text_vectorizer, train_dataset, val_dataset, d_feature=128, lr=0.01, train_steps=5):\n",
    "    \"\"\"Training the Siamese Model\n",
    "\n",
    "    Args:\n",
    "        Siamese (function): Function that returns the Siamese model.\n",
    "        TripletLoss (function): Function that defines the TripletLoss loss function.\n",
    "        text_vectorizer: trained instance of `TextVecotrization` \n",
    "        train_dataset (tf.data.Dataset): Training dataset\n",
    "        val_dataset (tf.data.Dataset): Validation dataset\n",
    "        d_feature (int, optional) = size of the encoding. Defaults to 128.\n",
    "        lr (float, optional): learning rate for optimizer. Defaults to 0.01\n",
    "        train_steps (int): number of epochs\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Siamese(text_vectorizer,\n",
    "                    vocab_size = text_vectorizer.vocabulary_size(),\n",
    "                    d_feature = d_feature)\n",
    "    # Compile the model\n",
    "    model.compile(loss=TripletLoss,\n",
    "                  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            )\n",
    "    # Train the model \n",
    "    model.fit(train_dataset,\n",
    "              epochs = train_steps,\n",
    "              validation_data = val_dataset,\n",
    "             )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_steps = 1\n",
    "batch_size = 256\n",
    "train_generator = train_dataset.shuffle(len(train_Q1),\n",
    "                                        seed=7, \n",
    "                                        reshuffle_each_iteration=True).batch(batch_size=batch_size)\n",
    "val_generator = val_dataset.shuffle(len(val_Q1), \n",
    "                                   seed=7,\n",
    "                                   reshuffle_each_iteration=True).batch(batch_size=batch_size)\n",
    "# model = train_model(Siamese, TripletLoss,text_vectorization, \n",
    "#                                             train_generator, \n",
    "#                                             val_generator, \n",
    "#                                             train_steps=train_steps,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model/trained_model.keras', safe_mode=False, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "K-h6ZH507fUm",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def classify(test_Q1, test_Q2, y_test, threshold, model, batch_size=64, verbose=True):\n",
    "    \"\"\"Function to test the accuracy of the model.\n",
    "\n",
    "    Args:\n",
    "        test_Q1 (numpy.ndarray): Array of Q1 questions. Each element of the array would be a string.\n",
    "        test_Q2 (numpy.ndarray): Array of Q2 questions. Each element of the array would be a string.\n",
    "        y_test (numpy.ndarray): Array of actual target.\n",
    "        threshold (float): Desired threshold\n",
    "        model (tensorflow.Keras.Model): The Siamese model.\n",
    "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model\n",
    "        numpy.array: confusion matrix\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    test_gen = tf.data.Dataset.from_tensor_slices(((test_Q1, test_Q2),None)).batch(batch_size=batch_size)\n",
    "\n",
    "    pred = model.predict(test_gen)\n",
    "    _, n_feat = pred.shape\n",
    "    v1 = pred[:, :n_feat//2]\n",
    "    v2 = pred[:, n_feat//2:]\n",
    "    \n",
    "    d  = tf.math.reduce_sum(v1*v2, axis=1)\n",
    "    y_pred = tf.cast(d > threshold, tf.float64)\n",
    "    accuracy = tf.math.reduce_mean(tf.cast(y_pred == y_test, tf.float64))\n",
    "    cm = tf.math.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "yeQjHxkfpivH",
    "outputId": "103b8449-896f-403d-f011-583df70afdae",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step\n",
      "Accuracy 0.7259765625\n",
      "Confusion matrix:\n",
      "[[4876 1506]\n",
      " [1300 2558]]\n"
     ]
    }
   ],
   "source": [
    "accuracy, cm = classify(Q1_test,Q2_test, y_test, 0.7, model,  batch_size = 512) \n",
    "print(\"Accuracy\", accuracy.numpy())\n",
    "print(f\"Confusion matrix:\\n{cm.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "kg0wQ8qhpivL",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def predict(question1, question2, threshold, model, verbose=False):\n",
    "    \"\"\"Function for predicting if two questions are duplicates.\n",
    "\n",
    "    Args:\n",
    "        question1 (str): First question.\n",
    "        question2 (str): Second question.\n",
    "        threshold (float): Desired threshold.\n",
    "        model (tensorflow.keras.Model): The Siamese model.\n",
    "        verbose (bool, optional): If the results should be printed out. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the questions are duplicates, False otherwise.\n",
    "    \"\"\"\n",
    "    generator = tf.data.Dataset.from_tensor_slices((([question1], [question2]),None)).batch(batch_size=1)\n",
    "    \n",
    "    v1v2 = model.predict(generator)\n",
    "    v1 = v1v2[:, :v1v2.shape[1]//2]\n",
    "    v2 = v1v2[:, v1v2.shape[1]//2:]\n",
    "\n",
    "    d = tf.math.reduce_sum(v1*v2)\n",
    "    res = d > threshold\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"Q1  = \", question1, \"\\nQ2  = \", question2)\n",
    "        print(\"d   = \", d.numpy())\n",
    "        print(\"res = \", res.numpy())\n",
    "\n",
    "    return res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Raojyhw3z7HE",
    "outputId": "b0907aaf-63c0-448d-99b0-012359381a97",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q1  =  When will I see you? \n",
      "Q2  =  When can I see you again?\n",
      "d   =  0.8422112\n",
      "res =  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1 = \"When will I see you?\"\n",
    "question2 = \"When can I see you again?\"\n",
    "# 1 means it is duplicated, 0 otherwise\n",
    "predict(question1 , question2, 0.7, model, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "DZccIQ_lpivQ",
    "outputId": "3ed0af7e-5d44-4eb3-cebe-d6f74abe3e41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q1  =  Do they enjoy eating the dessert? \n",
      "Q2  =  Do they like hiking in the desert?\n",
      "d   =  0.12625802\n",
      "res =  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1 = \"Do they enjoy eating the dessert?\"\n",
    "question2 = \"Do they like hiking in the desert?\"\n",
    "predict(question1 , question2, 0.7, model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "C3_W4_Assignment_Solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "coursera": {
   "schema_names": [
    "NLPC3-4A"
   ]
  },
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
